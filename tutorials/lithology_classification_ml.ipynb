{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lithology classification\n",
    "\n",
    "## Data\n",
    "\n",
    "This notebook uses data from the [Upper Condamine Catchment](http://www.bom.gov.au/qld/flood/brochures/condamine_balonne/map_upper.shtml) in the state of Queensland. The data is sourced from personal communication as a project output. It may be shared publicly and downloadable from this sample notebook in the future.\n",
    "\n",
    "![Upper Condamine catchment formations](img/Upper_Condamine_formations.png \"Upper Condamine catchment formations\")\n",
    "\n",
    "(Figure from [this paper](https://www.researchgate.net/figure/Upper-Condamine-catchment-Queensland-Australia-The-Marburg-Subgroup-consists-of_fig1_283184727))\n",
    "\n",
    "## Status\n",
    "\n",
    "As of May 2019 this present document is an output from exploratory work done during an internship by [Sudhir Gupta](https://github.com/Sudhir22).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook compares the performance of two techniques for semi-automated classification . It also summarise work using ontologies for classification for cases where we do not have reliable training sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:54:38.357642Z",
     "start_time": "2018-02-27T01:54:36.460827Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only True for co-dev of ela from this use case:\n",
    "ela_from_source = False\n",
    "ela_from_source = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ela_from_source:\n",
    "    if ('ELA_SRC' in os.environ):\n",
    "        root_src_dir = os.environ['ELA_SRC']\n",
    "    elif sys.platform == 'win32':\n",
    "        root_src_dir = r'C:\\Users\\SUD011\\Documents\\pyela-sudhir'\n",
    "    else:\n",
    "        username = os.environ['USER']\n",
    "        root_src_dir = os.path.join('/home', username, 'src/github_jm/pyela')\n",
    "    pkg_src_dir = root_src_dir\n",
    "    sys.path.append(pkg_src_dir)\n",
    "\n",
    "from ela.textproc import *\n",
    "from ela.utils import *\n",
    "from ela.classification import *\n",
    "from ela.visual import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import striplog\n",
    "from striplog import Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('ELA_DATA' in os.environ):\n",
    "    data_path = os.environ['ELA_DATA']\n",
    "elif sys.platform == 'win32':\n",
    "    data_path = r'C:\\data\\Lithology'\n",
    "else:\n",
    "    username = os.environ['USER']\n",
    "    data_path = os.path.join('/home', username, 'data', 'Lithology')\n",
    "\n",
    "condamine_litho_dir = os.path.join(data_path,'Condamine')\n",
    "condamine_litho_xl = os.path.join(condamine_litho_dir, 'MASTER_CONDAMINE_Interpretation_all_combined_Jan2017.xlsx')\n",
    "condamine_litho_pkl = os.path.join(condamine_litho_dir, 'MASTER_CONDAMINE_Interpretation_all_combined_Jan2017.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data exploration\n",
    "\n",
    "This first section deliberately covers some of the data discovery process for didactic purposes.\n",
    "\n",
    "## Useful resources\n",
    "\n",
    "Note that some of the terms used for classification are triangulated with [this description](https://www.bioregionalassessments.gov.au/assessments/21-22-data-analysis-clarence-moreton-bioregion/21211-lithological-and-stratigraphic-data)\n",
    "\n",
    "We cache the data in a pickle as it is faster to re-read:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(condamine_litho_pkl):\n",
    "    train_data=pd.read_excel(condamine_litho_xl)\n",
    "    with open(condamine_litho_pkl, 'wb') as handle:\n",
    "        pickle.dump(train_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(condamine_litho_pkl, 'rb') as handle:\n",
    "        train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_unprocessed = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data\n",
    "LITHO_DESC_COL='Lithology_original'\n",
    "REGEX_LITHO_CLASS_COL='Regex_lithoclass'\n",
    "\n",
    "LITHO_CLASS_COL = 'Simplified_lithology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_data[LITHO_CLASS_COL].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We massage the column of simplified lithologies, resulting from a manual classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not obvious from inspection of the the pandas  data frame, but there appears to be NaNs that cause headaches later on.\n",
    "vv = [x for x in df[LITHO_DESC_COL].values if not type(x) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = [type(x) is not str for x in df[LITHO_DESC_COL].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[np.array(vv)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].replace(np.nan,'',regex=True)\n",
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].str.lower()\n",
    "train_data[LITHO_DESC_COL] = train_data[LITHO_DESC_COL].replace(np.nan,'',regex=True)\n",
    "train_data[LITHO_DESC_COL] = train_data[LITHO_DESC_COL].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Not obvious upfront but noticed that there are terms where dots and slashes prevent tokenization and lithology term detection. \n",
    "train_data[LITHO_DESC_COL] = v_replace_punctuations(train_data[LITHO_DESC_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq(train_data[LITHO_CLASS_COL].values, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the low frequency of some of the classes, we remap them to one of the three main classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].replace('granite|granodiorite|diorite|basement','bedrock',regex=True)\n",
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].replace('gravel','alluvium',regex=False)\n",
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].replace('wrong_location|weathering_horizon|tertiary','unknown',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq(train_data[LITHO_CLASS_COL].values, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = df[LITHO_DESC_COL]\n",
    "descs = descs.reset_index()\n",
    "descs = descs[LITHO_DESC_COL]\n",
    "descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = Lexicon.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "expanded_descs = descs.apply(lex.expand_abbreviations)\n",
    "y = expanded_descs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[LITHO_DESC_COL] = expanded_descs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We flatten the corpus of words to get the most frequend terms as a guide for which lithology classes we can define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "flat = flat_list_tokens(y)\n",
    "len(set(flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common= token_freq(flat, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(df_most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condamine_litho_cleaned_pkl = os.path.join(condamine_litho_dir, 'condamine_litho_cleaned.pkl')\n",
    "\n",
    "if not os.path.exists(condamine_litho_cleaned_pkl):\n",
    "    with open(condamine_litho_cleaned_pkl, 'wb') as handle:\n",
    "        pickle.dump(train_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(condamine_litho_cleaned_pkl, 'rb') as handle:\n",
    "        train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining lithology classes\n",
    "\n",
    "Starting with the three terms we want to end up with, we can also add the most frequent terms observed in the corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies = ['alluvium', 'basalt', 'bedrock', 'clay', 'sandstone','sand','shale','soil','honeycomb','gravel','coal','gravel','silt','soil','rock', 'limestone', 'metal']\n",
    "# see https://www.bioregionalassessments.gov.au/assessments/21-22-data-analysis-clarence-moreton-bioregion/21211-lithological-and-stratigraphic-data\n",
    "# for 'metal' or 'blue metal'\n",
    "any_litho_markers_re = r'alluvium|sand|clay|ston|shale|basa|silt|soil|honey|coal|gravel|rock|mud|metal'\n",
    "\n",
    "regex = re.compile(any_litho_markers_re)\n",
    "\n",
    "lithologies_dict = dict([(x,x) for x in lithologies])\n",
    "lithologies_dict['sands'] = 'sand'\n",
    "lithologies_dict['basalts'] = 'basalt'\n",
    "lithologies_dict['clays'] = 'clay'\n",
    "lithologies_dict['shales'] = 'shale'\n",
    "lithologies_dict['claystone'] = 'clay'\n",
    "lithologies_dict['siltstone'] = 'silt'\n",
    "lithologies_dict['mudstone'] = 'silt' # ??\n",
    "lithologies_dict['capstone'] = 'limestone' # ??\n",
    "lithologies_dict['ironstone'] = 'sandstone' # ??\n",
    "lithologies_dict['topsoil'] = 'soil' # ??\n",
    "\n",
    "lithologies_adjective_dict = {\n",
    "    'sandy' :  'sand',\n",
    "    'clayey' :  'clay',\n",
    "    'clayish' :  'clay',\n",
    "    'shaley' :  'shale',\n",
    "    'silty' :  'silt',\n",
    "    'gravelly' :  'gravel'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "v_tokens = v_word_tokenize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vt = v_find_litho_markers(v_tokens, regex=regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mark = len([x for x in vt if len(x) == 0 ])\n",
    "at_least_one_mark = len([x for x in vt if len(x) >= 1])\n",
    "at_least_two_mark = len([x for x in vt if len(x) >= 2])\n",
    "print('There are %s entries with no marker, %s entries with at least one, %s with at least two'%(zero_mark,at_least_one_mark,at_least_two_mark))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the regular expression model on the Condamine dataset\n",
    "\n",
    "We have one first pass at classifying into one of the three target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_litho = [find_primary_lithology(x, lithologies_dict) for x in vt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(set(prim_litho))\n",
    "plot_freq(token_freq(prim_litho, n_most_common = n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a map of classes down to alluvium, bedrock, basalt or unknown.\n",
    "\n",
    "We will do a bit of \"snooping\" on the labelled data; this is not ideal but is necessary to validate some classification assumptions.\n",
    "\n",
    "Given the a priori classification of primary lithologies, what proportions of labels do we have for each primary lithologhy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame({ LITHO_CLASS_COL: train_data[LITHO_CLASS_COL], REGEX_LITHO_CLASS_COL: prim_litho, LITHO_DESC_COL: descs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_freq_for_lithology(litho_name):\n",
    "    blah = tmp_df.loc[tmp_df[REGEX_LITHO_CLASS_COL] == litho_name]\n",
    "    return token_freq(blah[LITHO_CLASS_COL].values, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_for_lithology('clay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_for_lithology('sand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_for_lithology('soil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_for_lithology('honeycomb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_for_lithology('shale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_for_lithology('coal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_for_lithology('gravel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_for_lithology('silt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_map={\n",
    "    'alluvium' :  'alluvium',\n",
    "    'bedrock' :  'bedrock',\n",
    "    'basalt' :  'basalt',\n",
    "    'metal' :  'basalt',\n",
    "    'honeycomb' :  'basalt',\n",
    "    'clay' :  'alluvium',\n",
    "    'coal' :  'bedrock', \n",
    "    'sandstone' :  'bedrock',\n",
    "    'sand' :  'alluvium',\n",
    "    '' :  'unknown',\n",
    "    'soil' :  'alluvium',\n",
    "    'shale': 'bedrock',\n",
    "    'gravel': 'alluvium',\n",
    "    'silt' : 'bedrock',\n",
    "    'rock' : 'bedrock',\n",
    "    'limestone' : 'alluvium'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prim_litho=list()\n",
    "for x in prim_litho:\n",
    "    final_prim_litho.append(lithology_map[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq(final_prim_litho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_lithology=train_data[LITHO_CLASS_COL].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(modelled, expected):\n",
    "    matches = np.equal(modelled, expected)\n",
    "    return np.count_nonzero(matches)/len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of regex for classifying primary lithologies: \", get_accuracy(final_prim_litho, simplified_lithology))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what lithology descriptions led to an 'unknown' classification to see whether we are missing something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame({ LITHO_CLASS_COL: train_data[LITHO_CLASS_COL], REGEX_LITHO_CLASS_COL: final_prim_litho, LITHO_DESC_COL: descs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_and_sample_df(tmp_df, 'unknown', colname=REGEX_LITHO_CLASS_COL, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unk = tmp_df.loc[ tmp_df[REGEX_LITHO_CLASS_COL] == 'unknown' ]\n",
    "df_unk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flat_list_tokens(df_unk[LITHO_DESC_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(s, title = 'Unclassified via regexp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(token_freq(flat, n_most_common = 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not use 'loam' as a term. There are others that should be used, but it is unclear how they should be remapped, like \"metal\" and \"file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies.append('loam')\n",
    "lithologies.append('granite')\n",
    "lithologies.append('soapstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_litho_markers_re = any_litho_markers_re + '|loam|granite|soap'\n",
    "regex = re.compile(any_litho_markers_re)\n",
    "lithologies_dict['loam'] = 'loam'\n",
    "lithologies_dict['granite'] = 'granite'\n",
    "lithologies_dict['soapstone'] = 'soapstone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tokens = v_word_tokenize(y)\n",
    "vt = v_find_litho_markers(v_tokens, regex=regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_litho = [find_primary_lithology(x, lithologies_dict) for x in vt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(set(prim_litho))\n",
    "plot_freq(token_freq(prim_litho, n_most_common = n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_map['loam'] = 'alluvium'\n",
    "lithology_map['granite'] = 'bedrock'\n",
    "lithology_map['soapstone'] = 'bedrock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prim_litho=list()\n",
    "for x in prim_litho:\n",
    "    final_prim_litho.append(lithology_map[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq(final_prim_litho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame({ LITHO_CLASS_COL: train_data[LITHO_CLASS_COL], REGEX_LITHO_CLASS_COL: final_prim_litho, LITHO_DESC_COL: descs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_and_sample_df(tmp_df, 'unknown', colname=REGEX_LITHO_CLASS_COL, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of regex for classifying primary lithologies: \", get_accuracy(final_prim_litho, simplified_lithology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame({ LITHO_CLASS_COL: train_data[LITHO_CLASS_COL], REGEX_LITHO_CLASS_COL: final_prim_litho, LITHO_DESC_COL: descs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unk = tmp_df.loc[ tmp_df[REGEX_LITHO_CLASS_COL] == 'unknown' ]\n",
    "df_unk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flat_list_tokens(df_unk[LITHO_DESC_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(s, title = 'Unclassified via regexp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_matches(x, regex):\n",
    "    return (regex.match(x) is not None)\n",
    "\n",
    "def find_regex_df(df, expression, colname):\n",
    "    \"\"\"Sample a random subset of rows where the lithology column matches a particular class name.\n",
    "\n",
    "        Args:\n",
    "            df (pandas data frame): bore lithology data  with columns named PRIMARY_LITHO_COL\n",
    "    \n",
    "        Returns:\n",
    "            dataframe:\n",
    "    \"\"\"\n",
    "    tested = df[colname].values\n",
    "    regex = re.compile(expression)\n",
    "    xx = [(regex.match(x) is not None) for x in tested]\n",
    "    df_test = df.loc[xx]\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_regex_df( df_unk, '.*basalt.*', LITHO_DESC_COL)\n",
    "# find_regex_df( df_unk, '.*file.*', LITHO_DESC_COL)\n",
    "\n",
    "match_and_sample_df(tmp_df, 'unknown', colname=REGEX_LITHO_CLASS_COL, out_colname=None, size=50, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regex = df.copy()\n",
    "df_regex[REGEX_LITHO_CLASS_COL] = final_prim_litho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condamine_litho_regex = os.path.join(condamine_litho_dir, 'condamine_litho_regex.pkl')\n",
    "with open(condamine_litho_regex, 'wb') as handle:\n",
    "    pickle.dump(df_regex, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the deep learning model on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data=train_data_unprocessed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install gensim\n",
    "# conda install tensorflow\n",
    "# conda install keras\n",
    "# pip install wordcloud\n",
    "\n",
    "from ela.experiment.textproc import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dl = train_data.copy()\n",
    "model=Model(train_data_dl,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initialise_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of 2019-07-20: \n",
    "\n",
    "* Training Accuracy: 0.8620\n",
    "* Testing Accuracy:  0.8562\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.copy()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Description'] = x['Lithology_original']\n",
    "#model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dl = pd.read_csv('prediction_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of DL for classifying primary lithologies: \", get_accuracy(predictions_dl['Simplified_Lithology'], simplified_lithology))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the predictive performance of regexp versus DL\n",
    "\n",
    "* Confusion matrices for RE and DL\n",
    "* Subset each case where DL gets is right and not RE, and get a wordcloud of terms\n",
    "* Subset each case where RE gets is right and not DL, and get a wordcloud of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "\n",
    "condamine_litho_regex = os.path.join(condamine_litho_dir, 'condamine_litho_regex.pkl')\n",
    "with open(condamine_litho_regex, 'rb') as handle:\n",
    "    df_regex = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_regex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_class_names = [\"basalt\", \"bedrock\", \"alluvium\", \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(df_regex, colname_true, colname_predicted, labels = litho_class_names):\n",
    "    y_true = df_regex[colname_true].values\n",
    "    y_pred = df_regex[colname_predicted].values    \n",
    "    m = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    return m\n",
    "\n",
    "def normalise_confusion_matrix(m):\n",
    "    fractions = m / m.astype(np.float).sum(axis=0)\n",
    "    return fractions\n",
    "\n",
    "def plot_cf_matrix(m, litho_class_names, title='confusion matrix', figsize = (10,7), cmap='coolwarm', center=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(m, index = [i for i in litho_class_names],\n",
    "                      columns = [i for i in litho_class_names])\n",
    "    plt.figure(figsize = figsize)\n",
    "    sn.heatmap(df_cm, annot=True, cmap=cmap, center=center)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('actual')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_regex = build_confusion_matrix(df_regex, colname_true=LITHO_CLASS_COL, colname_predicted=REGEX_LITHO_CLASS_COL)\n",
    "fractions_regex = normalise_confusion_matrix(m_regex)\n",
    "\n",
    "m_dl = build_confusion_matrix(predictions_dl, colname_true='Simplified_lithology', colname_predicted='Simplified_Lithology')\n",
    "fractions_dl = normalise_confusion_matrix(m_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_frac = fractions_dl - fractions_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(m_regex, litho_class_names, title='confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(fractions_regex, litho_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(m_dl, litho_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(fractions_dl, litho_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(diff_frac, litho_class_names, title='dl-regex confusion matrix comparison', cmap=\"PiYG\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf_matrix(diff_frac * 100, litho_class_names, title='dl-regex confusion matrix comparison', cmap='bwr', center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double-checking the normalisation procedure\n",
    "#true_counts = m.astype(np.float).sum(axis=1) # true preds\n",
    "#f = m / true_counts\n",
    "#f\n",
    "#f = m / m.astype(np.float).sum(axis=0)\n",
    "#f\n",
    "#f.sum(axis=0), f.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the accuracy if geolocation and log descriptions are taken as input features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression for classifying lithologies based on geolocation. Combining the outputs of the logistic regression model and the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_unprocessed.copy()\n",
    "set(train_data['Simplified_lithology'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Simplified_lithology']=train_data['Simplified_lithology'].replace(np.nan,'Unknown',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Simplified_lithology']=train_data['Simplified_lithology'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_data['Simplified_lithology'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Simplified_lithology'],labels=pd.factorize(train_data['Simplified_lithology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_data[['EASTING','NORTHING']][0:len(model.train_X)]\n",
    "test_X=train_data[['EASTING','NORTHING']][len(model.train_X):]\n",
    "train_y=train_data['Simplified_lithology'][0:len(model.train_X)]\n",
    "test_y=train_data['Simplified_lithology'][len(model.train_X):]\n",
    "train_X.replace(np.nan,0.0,inplace=True)\n",
    "test_X.replace(np.nan,0.0,inplace=True)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(C=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data_unprocessed.copy()\n",
    "new_df=pd.DataFrame(train_data[['Lithology_original']].values,columns=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[len(model.train_X):].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dl=model.predict_certainity(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pred_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_pred_dl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class_prob=np.mean(np.array([y_pred,y_pred_dl]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_class_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_numerical=np.argmax(final_class_prob,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(test_y,final_output_numerical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_lithology_categories=[]\n",
    "for x in final_output_numerical:\n",
    "    simplified_lithology_categories.append(labels[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not increase the accuracy. Don't think the geolocation has an impact on the simplified lithologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontology based learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides libraries such as RDFLib, OWL 2 for working with ontologies. OWL 2 is better suited for ontology oriented programming since it offers a more pythonic way of managing/creating ontologies.\n",
    "But then, RDFLib works well with .rdf files. Hence, there is a trade-off. Can use based on individual project needs. <br>\n",
    "\n",
    "Protege is an 'IDE' which can be used to manage/create ontologies. It was developed at Stanford and can be downloaded from here [Protege](https://protege.stanford.edu/)<br>\n",
    "Protege can be used to visualise the different relationships defined in an ontology <br>\n",
    "\n",
    "The ontology that I am using can be downloaded from [here](http://ontologydesignpatterns.org/wiki/Ontology:CGI_Simple_Lithology_201001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.namespace import SKOS\n",
    "from rdflib.namespace import RDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology=rd.Graph()\n",
    "condamine_litho_ontology = os.path.join(condamine_litho_dir, 'SimpleLithology201001.rdf')\n",
    "ontology.parse(condamine_litho_ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_dictionary=dict()\n",
    "for x,y in ontology.subject_objects(SKOS.prefLabel):\n",
    "    lithology_dictionary[x]=y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in ontology.subject_objects(SKOS.broader):\n",
    "    if x in lithology_dictionary.keys() and y in lithology_dictionary.keys():\n",
    "        print(\" broader class of \",lithology_dictionary[x],\" is \",lithology_dictionary[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>These relationships can be converted into fuzzy if-then rules and fed to the machine learning model to make better decisions. <br>\n",
    "Above is only one kind of relationship. We have other relationships such as narrower, description of each label etc. All these combined would make a very \"knowledgeable\" machine learning model. </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing visually\n",
    "\n",
    "Optional\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations and discussions\n",
    "\n",
    "DL much better than regular expressions.<br>\n",
    "\n",
    "Regular expressions use a set of keywords and look for matches in the descriptions. Sometimes, these keywords might not be in the descriptions.<br>\n",
    "\n",
    "Similarly, regular expressions map descriptions to a set of predefined catgories (clay,sand,etc.) which are further refined into broader categories ( alluvium,basalt,bedrock). Geoscientists confirm that the mapping is not one/many-to-one. For example,Clay could be part of alluvium/basalt. This cannot be achieved using the regular expression model.\n",
    "\n",
    "DL, on the other hand, learns the descriptions of different lithology classes. Based on labelled data from geoscientists, DL model learns the different kinds of descriptions which would pertain to for e.g alluvium. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and future work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ELA)",
   "language": "python",
   "name": "ela"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
