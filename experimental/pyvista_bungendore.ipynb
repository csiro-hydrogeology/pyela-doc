{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wellbore Paths in PyVista "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was adapted from a resource found online, but apparently now removed.\n",
    "\n",
    "This is an attempt to use pyvista and/or pvgeo to visualise borehole log data in the browser. \n",
    "\n",
    "compressed data for this notebook is available for download from [this link](https://cloudstor.aarnet.edu.au/plus/s/gTAVfJZ5Dve15ud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to import `pandas` for reading in our well data, `numpy` for making stratigraphic surfaces, `pyvista` and `PVGeo` for visualization. Also we are going to set the `panel.extension` to `'vtk'` and set the `pyvista` theme to `document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import panel\n",
    "import PVGeo\n",
    "\n",
    "panel.extension(\"vtk\")\n",
    "pv.set_plot_theme(\"document\")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "ela_from_source = False\n",
    "ela_from_source = True\n",
    "\n",
    "if ela_from_source:\n",
    "    if ('ELA_SRC' in os.environ):\n",
    "        root_src_dir = os.environ['ELA_SRC']\n",
    "    elif sys.platform == 'win32':\n",
    "        root_src_dir = r'C:\\Users\\SUD011\\Documents\\pyela-sudhir'\n",
    "    else:\n",
    "        username = os.environ['USER']\n",
    "        root_src_dir = os.path.join('/home', username, 'src/github_jm/pyela')\n",
    "    pkg_src_dir = root_src_dir\n",
    "    sys.path.insert(0, pkg_src_dir)\n",
    "\n",
    "from ela.textproc import *\n",
    "from ela.utils import *\n",
    "from ela.classification import *\n",
    "from ela.visual import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Global settings and preprocessed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('ELA_DATA' in os.environ):\n",
    "    data_path = os.environ['ELA_DATA']\n",
    "elif sys.platform == 'win32':\n",
    "    data_path = r'C:\\data\\Lithology'\n",
    "else:\n",
    "    username = os.environ['USER']\n",
    "    data_path = os.path.join('/home', username, 'data', 'Lithology')\n",
    "\n",
    "# to be reused in experimental notebooks:\n",
    "classified_logs_filename = os.path.join(data_path, 'Bungendore','classified_logs.pkl')\n",
    "df = pd.read_pickle(classified_logs_filename)\n",
    "# df = pd.read_pickle(os.path.join(data_path, 'data_inter', 'above_leederville.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "bungendore_datadir = os.path.join(data_path, 'Bungendore')\n",
    "fp = os.path.join(bungendore_datadir, 'dem_array_data.pkl')\n",
    "with open(fp, 'rb') as handle:\n",
    "    dem_array_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_logs_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the data using `pandas` and get a quick look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the names of the wells from the data and assign them to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_heights_colname = 'scaled_z'\n",
    "data[scaled_heights_colname]  = data[DEPTH_FROM_AHD_COL] * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['BoreID', scaled_heights_colname, DEPTH_FROM_AHD_COL]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ref_colname='name'\n",
    "#data.index.values.astype(str)\n",
    "data[site_ref_colname]=data.BoreID.values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = data.name.unique()\n",
    "# wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to go through the data and build a `dict` for each well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out the wells into a dictionary\n",
    "well_dict = {}\n",
    "for well in wells:\n",
    "    well_dict[\"{0}\".format(well)] = data[data.name == well]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's take each well in the `well_dict` and get the points referenced to one another so they all plot up in real space relative to one another. We are then creating a `numpy` array with the `'easting'` (x-value), the `'northing'` (y-value), and the `depth` which is our true vertical depth. We now have each entry in the `points_dict` with an x, y, and z value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now turn the wells into points\n",
    "points_dict = {}\n",
    "for points in well_dict:\n",
    "    points_dict[\"{0}\".format(points)] = np.array(\n",
    "        list(\n",
    "            zip(\n",
    "                well_dict[points].Easting ,\n",
    "                well_dict[points].Northing,\n",
    "                well_dict[points][scaled_heights_colname],\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_dict[points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(well_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_dict[points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the points we want to create `PolyData` to plot in `PyVista`. To create this `PolyData` we use `PVGeo.points_to_poly_data()` on each entry in the `points_dict`. Then we use `PVGeo.filters.AddCellConnToPoints` to create cells connecting the points. At this point we have everything we need to plot up wellbore trajectories. But let's have some fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now turn points into polydata\n",
    "lines_dict = {}\n",
    "for lines in points_dict:\n",
    "    poly = PVGeo.points_to_poly_data(points_dict[lines])\n",
    "    lines_dict[\n",
    "        \"{0}\".format(lines)\n",
    "    ] = PVGeo.filters.AddCellConnToPoints().apply(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in lines_dict.keys()][0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To color and size the `PolyData` by a value we use the `GR` column from the original dataset. We assigne the `GR` gamma-ray values to each `PolyData` object meaning we now have `DataArrays` for each well that we can use to color our wellbore. Finally, we use `.tube()` to create tubes at each point with radius 10 that scale with the `GR` gamma-ray values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_class_col = 'Lithology_1_num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '10109370'\n",
    "data[data[site_ref_colname] == path][litho_class_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict_tmp = {}\n",
    "\n",
    "for path in lines_dict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[site_ref_colname] == path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_class_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='10109370'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = data[data[site_ref_colname] == path][litho_class_col].values\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict[path][\"GR\"] = vals\n",
    "lines_dict[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict[path].tube(radius=10, scalars=\"GR\", inplace=True)\n",
    "if len(vals) > 1:\n",
    "    lines_dict_tmp[path] = lines_dict[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict_tmp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in lines_dict:\n",
    "    vals = data[data[site_ref_colname] == path][litho_class_col].values\n",
    "    lines_dict[path][\"GR\"] = vals\n",
    "    lines_dict[path].tube(radius=10, scalars=\"GR\", inplace=True)\n",
    "    if len(vals) > 1:\n",
    "        lines_dict_tmp[path] = lines_dict[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict = lines_dict_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '61470318'\n",
    "lines_dict[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '61400032'\n",
    "lines_dict[path]\n",
    "len(data[data[site_ref_colname] == path][litho_class_col].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could plot up the wellbores at this point and have a great plot, but let's make some stratigraphic surfaces. I grabbed some tops from the [COGCC](https://cogcc.state.co.us) website for one of these wells. To make surfaces we need `x` and `y` values spanning the area we are interested in. So I use the minimum and maximum from the dataset and then add 1,000 feet in the x and y direction for the surfaces. Next we use `meshgrid` and create our grid. Then for each surface I create an empty array using `np.empty()` and `.fill` it with the depth to each top. For the last step for each surface we use `StructuredGrid` to create a structured `PolyData` grid. Here we have the Niobrara, Shannon, Sussex, Parkman, and Pierre formation tops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Easting.max() - data.Easting.min(),  (data.Northing.max() - data.Northing.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(\n",
    "    data.Easting.min() - 1000,\n",
    "    data.Easting.max() + 1000,\n",
    "    100,\n",
    ")\n",
    "y = np.arange(\n",
    "    data.Northing.min() - 1000,\n",
    "    data.Northing.max() + 1000,\n",
    "    100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pie = np.empty(r.shape)\n",
    "# pie.fill(-2267)\n",
    "# pierregrid = pv.StructuredGrid(x, y, pie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that work and now we get so see how it turned out! We start by creating our `Plotter` and then `add_mesh` for each pice of `PolyData` that we have created so far. Lastly, we call `.show()` and we have an interactive set of wells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = pv.Plotter()\n",
    "for well in lines_dict:\n",
    "    plotter.add_mesh(lines_dict[well])\n",
    "\n",
    "#plotter.add_mesh(pierregrid, opacity=0.5, color=\"green\")\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well, lines_dict[well]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphinx_gallery_thumbnail_number = 2\n",
    "from pyvista import examples# sphinx_gallery_thumbnail_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load St Helens DEM and warp the topography\n",
    "mesh = examples.download_st_helens()\n",
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = mesh.warp_by_scalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First a default plot with jet colormap\n",
    "p = pv.Plotter()\n",
    "# Add the data, use active scalar for coloring, and show the scalar bar\n",
    "p.add_mesh(mesh)\n",
    "# Display the scene\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_res = dem_array_data['grid_res']\n",
    "x_min, x_max, y_min, y_max = dem_array_data['bounds']\n",
    "xx, yy = dem_array_data['mesh_xy']\n",
    "dem_array = dem_array_data['dem_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlab.figure(size=(800, 800))\n",
    "# mlab.surf(xx, yy, dem_array, warp_scale=20, colormap='terrain')\n",
    "# mlab.outline()\n",
    "# mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = pv.StructuredGrid(xx, yy, dem_array * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this grid does not look like the one with the MT Saint Helen data set. How do I get the elevation values and a terrain coloring of voxels?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First a default plot with jet colormap\n",
    "p = pv.Plotter()\n",
    "# Add the data, use active scalar for coloring, and show the scalar bar\n",
    "p.add_mesh(grid)\n",
    "# Display the scene\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not at all clear what this is for. I tried to work by similarity possibly from \n",
    "# https://docs.pyvista.org/examples/00-load/create-structured-surface.html?highlight=plot_curvature\n",
    "\n",
    "grid.plot_curvature(clim=[-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix trial stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected frustrating to do something simple like an overlay in Python (yearning for R's ggmap). Google with keywords \"overlay a rasterio with geopandas points\".\n",
    "For future reference perhaps https://geohackweek.github.io/vector/06-geopandas-advanced/  . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gis.stackexchange.com/questions/294072/how-can-i-superimpose-a-geopandas-dataframe-on-a-raster-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract a portion of the dem over the bounding box of the groundwater areas of interest, and save DEM data as numpy arrays that will be more convenient to work with in mayavi (with x=easting and y=northing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista\n",
    "import PVGeo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets the plotting theme of `vtki` to look just like a ParaView rendering\n",
    "#vtki.set_plot_theme('paraview')\n",
    "#vtki.rcParams['cmap'] = 'bwr_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lithology",
   "language": "python",
   "name": "ela"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
